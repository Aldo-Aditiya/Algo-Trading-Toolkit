{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b99a99ad-6a06-42b2-9074-13de47638e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import pandas_ta as ta\n",
    "import quantstats as qs\n",
    "qs.extend_pandas()\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "\n",
    "params = {'figure.facecolor': 'w'}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e735d5b-5d02-40c6-961d-07887cf6a250",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0f8b55-026d-45fa-b573-265f4519e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Functions\n",
    "def handle_nan(df, method='bfill'):\n",
    "    ## Fill NaN values with the earliest data\n",
    "    if method == 'bfill':\n",
    "        return df.fillna(method='bfill', axis=0)\n",
    "    elif method == 'zerofill':\n",
    "        return df.fillna(0)\n",
    "    elif method == 'drop':\n",
    "        return df.dropna()\n",
    "\n",
    "def extend_price_df(df):\n",
    "    '''\n",
    "    Calculates returns, log_returns, and log_prices to a df with 'price' column\n",
    "    '''\n",
    "    df['log-price'] = np.log(df['price'])\n",
    "    df['return'] = df['price'].pct_change()\n",
    "    df['log-return'] = np.log(1 + df['return'])\n",
    "    \n",
    "    df = handle_nan(df, method='zerofill')\n",
    "    \n",
    "    return df\n",
    "     \n",
    "def gen_combined_df(df_dict, dict_keys, col, nan_handle_method='bfill'):\n",
    "    for i, key in enumerate(dict_keys):\n",
    "        if i == 0:\n",
    "            df_buff = pd.DataFrame(index=df_dict[key].index)\n",
    "        for c in col:\n",
    "            df_buff[key + '_' + c] = df_dict[key][c]\n",
    "    \n",
    "    # Handle NaN values from combination of multiple tickers\n",
    "    # Assumes that NaN values because \"stock have not existed\" has been handled\n",
    "    df_buff = handle_nan(df_buff, method=nan_handle_method)\n",
    "    df_buff = handle_nan(df_buff, method='drop')\n",
    "            \n",
    "    return df_buff\n",
    "\n",
    "# Plotting Functions\n",
    "def tsplot(y, lags=None, figsize=(20, 8), style='bmh', title='Time Series Analysis Plots'):\n",
    "    # source: http://www.blackarbs.com/blog/time-series-analysis-in-python-linear-models-to-garch/11/1/2016#GARCH\n",
    "    \n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "    with plt.style.context(style):    \n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        layout = (3, 2)\n",
    "        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "        qq_ax = plt.subplot2grid(layout, (2, 0))\n",
    "        pp_ax = plt.subplot2grid(layout, (2, 1))\n",
    "        \n",
    "        y.plot(ax=ts_ax)\n",
    "        ts_ax.set_title(title)\n",
    "        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.05, zero=False, auto_ylims=True)\n",
    "        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.05, zero=False, auto_ylims=True)\n",
    "        sm.qqplot(y, line='s', ax=qq_ax)\n",
    "        qq_ax.set_title('QQ Plot')        \n",
    "        scs.probplot(y, sparams=(y.mean(), y.std()), plot=pp_ax)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26c94c-daa4-480e-a691-3a7ed202c375",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dccf9d-f766-4f35-aed2-d6ac7f1076df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbedc232-0984-4c62-a1eb-2ef519a81f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Directory\n",
    "data_dir = '/workspace/202205_idx-trading/_data/'\n",
    "lq45_dir = '/workspace/202205_idx-trading/_data/20220525_lq45/'\n",
    "lq45_index_file = data_dir + '20220525_lq45_index.csv'\n",
    "lq45_list = '20220525_lq45-list.txt'\n",
    "\n",
    "# Prepare Stock Tickers\n",
    "with open(data_dir + lq45_list, \"r\") as f:\n",
    "    lq45_tickers = f.read().split('\\n')\n",
    "\n",
    "## Prepare active tickers for international codes\n",
    "active_tickers = [f + '.JK' for f in lq45_tickers]\n",
    "active_tickers.append('LQ45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c125390-38a2-4a75-b392-83f47a47bee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 46/46 [00:01<00:00, 29.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare Time Series Data\n",
    "# TODO - Returns calculation need to be done after fill\n",
    "nan_handle_method = 'bfill'\n",
    "\n",
    "df_dict = {}\n",
    "for ticker in tqdm(active_tickers):\n",
    "    if ticker == 'LQ45':\n",
    "        df_dict[ticker] = pd.read_csv(lq45_index_file)\n",
    "    else:\n",
    "        df_dict[ticker] = pd.read_csv(lq45_dir + ticker + '.csv')\n",
    "    \n",
    "    ## Take Only Date and Adjusted Close\n",
    "    df_dict[ticker] = df_dict[ticker][['Date', 'Adj Close']]\n",
    "    df_dict['Date'] = pd.to_datetime(df_dict[ticker]['Date'])\n",
    "    df_dict[ticker].set_index(pd.DatetimeIndex(df_dict[ticker]['Date']), inplace=True)\n",
    "    \n",
    "    df_dict[ticker].drop('Date', axis=1, inplace=True)\n",
    "    \n",
    "    ## Convert Adj Close to price\n",
    "    df_dict[ticker]['price'] = df_dict[ticker]['Adj Close']\n",
    "    df_dict[ticker].drop('Adj Close', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a521abf-43a8-4678-b1e6-6dc2221725d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 46/46 [00:00<00:00, 56.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Separate Into In Sample and Out Sample\n",
    "date_start = '2009-01-01'\n",
    "date_breakpoint = '2019-01-01'\n",
    "\n",
    "nan_cnt_threshold = 252*2\n",
    "\n",
    "in_df = {}\n",
    "out_df = {}\n",
    "rmv_tickers = []\n",
    "for ticker in tqdm(active_tickers):\n",
    "    ## Take In Sample and Out Sample Data\n",
    "    in_df[ticker] = df_dict[ticker][(df_dict[ticker].index >= date_start) & \n",
    "                                                (df_dict[ticker].index < date_breakpoint)]\n",
    "    out_df[ticker] = df_dict[ticker][df_dict[ticker].index >= date_breakpoint]\n",
    "    \n",
    "    ## Check if there are too many NaN values\n",
    "    if in_df[ticker]['price'].isna().sum() > nan_cnt_threshold:\n",
    "        rmv_tickers.append(ticker)\n",
    "        continue\n",
    "    \n",
    "    ## Handle NaN Values\n",
    "    in_df[ticker] = handle_nan(in_df[ticker], method=nan_handle_method)\n",
    "    out_df[ticker] = handle_nan(out_df[ticker], method=nan_handle_method)\n",
    "    \n",
    "    ## Extend price to other values\n",
    "    in_df[ticker] = extend_price_df(in_df[ticker])\n",
    "    out_df[ticker] = extend_price_df(out_df[ticker])\n",
    "\n",
    "# Remove tickers that only have small amounts of data\n",
    "active_tickers = [t for t in active_tickers if t not in rmv_tickers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bcddc3-3ee9-40d1-a0a0-ab5b6fb6fbc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Exploration\n",
    "Cointegration exploration is done on in-sample data only, so out of sample data is purely for testing.\n",
    "\n",
    "*We will revisit cointegration testing on OOS data later on.\n",
    "\n",
    "Steps:\n",
    "- Test using existing engle-granger package. \n",
    "- Fit Ornstein-Uhlenbeck process to generate lambda (and subsequently, half life)\n",
    "- Do a separate OLS to get beta of (potentially) cointegrating pair. Visualize Mean Reversion to verify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e3c6c-f514-4d09-b4dd-0c11c9c56bf7",
   "metadata": {},
   "source": [
    "### Engle-Granger Cointegration Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a88cbcb8-cd39-4042-b25d-8bee34cc9ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def find_coint_pairs(df_dict, tickers, form='normal', form_type='price', alpha=0.05):\n",
    "    '''\n",
    "    Finds cointegrated pairs from df_dict serial data, based on given tickers.\n",
    "    '''\n",
    "    def coint_ticker_pick(pvalue_1, pvalue_2, tickers, i, j):\n",
    "        if pvalue_1 <= pvalue_2:\n",
    "            pvalue = pvalue_1\n",
    "            coint_tickers = [tickers[i], tickers[j]]\n",
    "        else:\n",
    "            pvalue = pvalue_2\n",
    "            coint_tickers = [tickers[j], tickers[i]]\n",
    "        \n",
    "        return pvalue, coint_tickers\n",
    "    \n",
    "    n = len(tickers)\n",
    "    pairs = []\n",
    "    pvalues = []\n",
    "    \n",
    "    for i in range(0, n):\n",
    "        for j in range(i+1, n):\n",
    "            \n",
    "            comb_df = gen_combined_df(df_dict, [tickers[i], tickers[j]], [form_type])\n",
    "            S1 = comb_df[tickers[i] + \"_\" + form_type]\n",
    "            S2 = comb_df[tickers[j] + \"_\" + form_type]\n",
    "                \n",
    "            if(form == 'normal'):\n",
    "                result_1 = coint(S1, S2)\n",
    "                pvalue_1 = result_1[1]\n",
    "                \n",
    "                result_2 = coint(S2, S1)\n",
    "                pvalue_2 = result_2[1]\n",
    "                \n",
    "                pvalue, coint_tickers = coint_ticker_pick(pvalue_1, pvalue_2, tickers, i, j)\n",
    "                \n",
    "            elif(form == 'ratio'):\n",
    "                result_1 = adfuller(S1/S2)\n",
    "                pvalue_1 = result_1[1]\n",
    "                \n",
    "                result_2 = adfuller(S2/S1)\n",
    "                pvalue_2 = result_2[1]\n",
    "                \n",
    "                pvalue, coint_tickers = coint_ticker_pick(pvalue_1, pvalue_2, tickers, i, j)\n",
    "                \n",
    "            if pvalue < alpha:\n",
    "                pairs.append(coint_tickers)\n",
    "                pvalues.append(pvalue)\n",
    "                      \n",
    "    return pairs, pvalues\n",
    "\n",
    "def calc_beta_ols(S2, S1, form_type='price'):\n",
    "    '''\n",
    "    Calculate beta from two series by doing regression.\n",
    "    '''\n",
    "    S1 = sm.add_constant(S1)\n",
    "    results = sm.OLS(S2, S1).fit()\n",
    "    S1 = S1[form_type]\n",
    "    b = results.params[form_type].values[0]\n",
    "    \n",
    "    return b\n",
    "\n",
    "def calc_half_life(S, form_type='price'):\n",
    "    '''\n",
    "    Calculate half life from a price series\n",
    "    '''\n",
    "    S_lag = S.shift(periods=1).iloc[1:]\n",
    "    S_diff = S.iloc[1:] - S_lag\n",
    "\n",
    "    S_lag = sm.add_constant(S_lag)\n",
    "    results = sm.OLS(S_diff, S_lag).fit()\n",
    "    S_lag = S_lag[form_type]\n",
    "    lbd = results.params[form_type].values[0]\n",
    "\n",
    "    hl = -np.log(2) / lbd\n",
    "    \n",
    "    return hl, lbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "65919ce7-cfd3-4034-95bd-afe61116ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare LQ45 Stock Indexes of the Same Group\n",
    "stock_groups = {\n",
    "    \"energy_and_mining\": ['BRPT.JK', 'HRUM.JK', 'MEDC.JK', 'PGAS.JK', 'TPIA.JK', 'ADRO.JK', 'ITMG.JK', 'PTBA.JK', 'INCO.JK', 'MDKA.JK', 'ANTM.JK'],\n",
    "    \"retail\": ['AMRT.JK', 'UNVR.JK', 'ERAA.JK', 'ASII.JK'],\n",
    "    \"food_agri\": ['CPIN.JK', 'JPFA.JK', 'ICBP.JK', 'INDF.JK'],\n",
    "    \"paper\": ['TKIM.JK', 'INKP.JK'],\n",
    "    \"finance\": ['BBCA.JK', 'BBNI.JK', 'BBRI.JK', 'BBTN.JK', 'BMRI.JK', 'BFIN.JK'],\n",
    "    \"media\": ['EMTK.JK', 'MNCN.JK'],\n",
    "    \"telcom\": ['EXCL.JK', 'TLKM.JK', 'TBIG.JK', 'TOWR.JK'],\n",
    "    \"tobacco\": ['GGRM.JK', 'HMSP.JK'],\n",
    "    \"construction\": ['INTP.JK', 'PTPP.JK', 'SMGR.JK', 'UNTR.JK', 'WIKA.JK', 'WSKT.JK'],\n",
    "    \"medical\": ['KLBF.JK', 'MIKA.JK']\n",
    "}\n",
    "\n",
    "# Filter to only those that are active\n",
    "for key, val in stock_groups.items():\n",
    "    stock_groups[key] = [t for t in val if t in active_tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7e4eded1-91d7-4bdb-a2e1-94a5da55cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 10/10 [02:03<00:00, 12.30s/it]\n"
     ]
    }
   ],
   "source": [
    "# Search for Coint Pair on Different Forms\n",
    "forms = ['normal', 'ratio']\n",
    "form_types = ['price', 'log-price']\n",
    "\n",
    "pair_l = []\n",
    "for key, val in tqdm(stock_groups.items()):\n",
    "    tickers = val\n",
    "    tickers.append('LQ45')\n",
    "    \n",
    "    for f in forms:\n",
    "        for ft in form_types:\n",
    "    \n",
    "            pairs, pvalues = find_coint_pairs(in_df, tickers, form=f, form_type=ft, alpha=0.025)\n",
    "            for pair, pvalue in zip(pairs, pvalues):\n",
    "                pair_l.append({\n",
    "                                'ticker_1': pair[0],\n",
    "                                'ticker_2': pair[1],\n",
    "                                'form': f,\n",
    "                                'form_type': ft,\n",
    "                                'eg_pvalue': pvalue\n",
    "                            })\n",
    "    \n",
    "pair_df = pd.DataFrame(pair_l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "74189500-906a-4c03-bf78-bc693d155428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Half-Life\n",
    "\n",
    "pair_l = []\n",
    "for _, row in pair_df.iterrows():\n",
    "    # Regression to get Beta for Price Spread Model\n",
    "    comb_df = gen_combined_df(in_df, [row['ticker_1'], row['ticker_2']], [row['form_type']])\n",
    "    \n",
    "    ## Rename Columns\n",
    "    S1 = comb_df[row['ticker_1'] + \"_\" + row['form_type']]\n",
    "    S1.name = row['form_type']\n",
    "    S2 = comb_df[row['ticker_2'] + \"_\" + row['form_type']]\n",
    "    S2.name = row['form_type']\n",
    "    \n",
    "    if row['form'] == 'normal':\n",
    "        b = calc_beta_ols(S2, S1, form_type=[row['form_type']])\n",
    "        spread = S2 - b * S1\n",
    "        \n",
    "    elif row['form'] == 'ratio':\n",
    "        spread = S1 / S2\n",
    "\n",
    "    # Ornstein-Uhlenbeck Formula to Calculate Half Life\n",
    "    hl, lbd = calc_half_life(spread, form_type=[row['form_type']])\n",
    "    \n",
    "    pair_l.append({\n",
    "                    'half_life': hl,\n",
    "                    'lambda': lbd\n",
    "                    })\n",
    "    \n",
    "pair_df = pd.concat([pair_df, pd.DataFrame(pair_l)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4b32d3ef-141c-4499-a5f9-20873d8ebe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Strategies that Takes too Long to be Profitable\n",
    "final_pair_df = pair_df[(pair_df['half_life'] < 80) & (pair_df['lambda'] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cd63d2bb-2bf2-4acd-9fe8-d2555cbfa018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Strategies that Takes too Long to be Profitable\n",
    "final_pair_df = pair_df[(pair_df['half_life'] < 80) & (pair_df['lambda'] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c6f735fc-2632-4e92-8600-3399a1e14cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_1</th>\n",
       "      <th>ticker_2</th>\n",
       "      <th>form</th>\n",
       "      <th>form_type</th>\n",
       "      <th>eg_pvalue</th>\n",
       "      <th>half_life</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ASII.JK</td>\n",
       "      <td>AMRT.JK</td>\n",
       "      <td>normal</td>\n",
       "      <td>log-price</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>57.528110</td>\n",
       "      <td>-0.012049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LQ45</td>\n",
       "      <td>ASII.JK</td>\n",
       "      <td>ratio</td>\n",
       "      <td>log-price</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>69.226235</td>\n",
       "      <td>-0.010013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BBRI.JK</td>\n",
       "      <td>BBCA.JK</td>\n",
       "      <td>normal</td>\n",
       "      <td>price</td>\n",
       "      <td>0.009189</td>\n",
       "      <td>29.316331</td>\n",
       "      <td>-0.023644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BMRI.JK</td>\n",
       "      <td>BBRI.JK</td>\n",
       "      <td>normal</td>\n",
       "      <td>price</td>\n",
       "      <td>0.005884</td>\n",
       "      <td>25.350943</td>\n",
       "      <td>-0.027342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BBRI.JK</td>\n",
       "      <td>BBCA.JK</td>\n",
       "      <td>normal</td>\n",
       "      <td>log-price</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>18.586656</td>\n",
       "      <td>-0.037293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BMRI.JK</td>\n",
       "      <td>BBCA.JK</td>\n",
       "      <td>normal</td>\n",
       "      <td>log-price</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>46.239844</td>\n",
       "      <td>-0.014990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BMRI.JK</td>\n",
       "      <td>BBRI.JK</td>\n",
       "      <td>normal</td>\n",
       "      <td>log-price</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>45.504225</td>\n",
       "      <td>-0.015233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BBCA.JK</td>\n",
       "      <td>BBRI.JK</td>\n",
       "      <td>ratio</td>\n",
       "      <td>price</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>18.079666</td>\n",
       "      <td>-0.038338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BBCA.JK</td>\n",
       "      <td>BBRI.JK</td>\n",
       "      <td>ratio</td>\n",
       "      <td>log-price</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>18.810227</td>\n",
       "      <td>-0.036849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LQ45</td>\n",
       "      <td>GGRM.JK</td>\n",
       "      <td>ratio</td>\n",
       "      <td>price</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>79.389956</td>\n",
       "      <td>-0.008731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LQ45</td>\n",
       "      <td>INTP.JK</td>\n",
       "      <td>ratio</td>\n",
       "      <td>price</td>\n",
       "      <td>0.020557</td>\n",
       "      <td>76.864768</td>\n",
       "      <td>-0.009018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker_1 ticker_2    form  form_type  eg_pvalue  half_life    lambda\n",
       "13  ASII.JK  AMRT.JK  normal  log-price   0.003506  57.528110 -0.012049\n",
       "15     LQ45  ASII.JK   ratio  log-price   0.000158  69.226235 -0.010013\n",
       "25  BBRI.JK  BBCA.JK  normal      price   0.009189  29.316331 -0.023644\n",
       "26  BMRI.JK  BBRI.JK  normal      price   0.005884  25.350943 -0.027342\n",
       "27  BBRI.JK  BBCA.JK  normal  log-price   0.000085  18.586656 -0.037293\n",
       "28  BMRI.JK  BBCA.JK  normal  log-price   0.007078  46.239844 -0.014990\n",
       "31  BMRI.JK  BBRI.JK  normal  log-price   0.002544  45.504225 -0.015233\n",
       "32  BBCA.JK  BBRI.JK   ratio      price   0.000004  18.079666 -0.038338\n",
       "35  BBCA.JK  BBRI.JK   ratio  log-price   0.000014  18.810227 -0.036849\n",
       "40     LQ45  GGRM.JK   ratio      price   0.000008  79.389956 -0.008731\n",
       "44     LQ45  INTP.JK   ratio      price   0.020557  76.864768 -0.009018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(final_pair_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5d275-39a7-42c7-9b7b-bd18bbaa0250",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ff59e-ea5c-4987-beae-b2007d24a122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912cfe8d-d07d-44eb-b617-3561d7d1e6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox as ljungbox\n",
    "\n",
    "def get_arima_best_order(df_logret, pq_rng=range(5), d_rng=range(2)):\n",
    "    best_aic = np.inf \n",
    "    arima_best_order = None\n",
    "    arima_best_mdl = None\n",
    "\n",
    "    for p in tqdm(pq_rng):\n",
    "        for d in d_rng:\n",
    "            for q in pq_rng:\n",
    "                tmp_mdl = smt.ARIMA(df_logret, \n",
    "                                    order=(p,d,q)).fit(method='innovations_mle')\n",
    "                tmp_aic = tmp_mdl.aic\n",
    "                if tmp_aic < best_aic:\n",
    "                    best_aic = tmp_aic\n",
    "                    arima_best_order = (p, d, q)\n",
    "                    arima_best_mdl = tmp_mdl\n",
    "    arima_resid = arima_best_mdl.resid\n",
    "    print(arima_best_mdl.summary())\n",
    "    \n",
    "    return arima_best_order, arima_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b332ce1-34ab-49cb-acf5-b58472e1b737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████▍                           | 3/5 [00:18<00:12,  6.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run ARIMA Fitting\n",
    "arima_best_order, arima_resid = get_arima_best_order(in_df[ticker]['log_return'])\n",
    "\n",
    "## Test Ljungbox Fit\n",
    "lb_pval = ljungbox(arima_resid, lags=[arima_best_order[2]])['lb_pvalue'].values[0]\n",
    "lb_pval_2 = ljungbox(arima_resid**2, lags=[arima_best_order[2]])['lb_pvalue'].values[0]\n",
    "print(f'Ljung-Box P-Value on Residual        : {lb_pval}')\n",
    "print(f'Ljung-Box P-Value on Squared Residual: {lb_pval_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef7082-2c1c-460a-a6bb-4befdb7d247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model Summary\n",
    "_ = tsplot(arima_resid, lags=30)\n",
    "_ = tsplot(arima_resid ** 2, lags=30, title='Squared Analysis Plot')\n",
    "\n",
    "# TODO - Find other goodness of fit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f955222-5ed7-41f9-a737-b916afbb080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def get_garch_1d_forecast(df_logret, arima_best_order):\n",
    "    # Prepare Input Files\n",
    "    ## ARIMA Model Best Order Fle\n",
    "    with open(\"arima_model.txt\", \"w+\") as f:\n",
    "        for item in arima_best_order:\n",
    "            f.writelines(str(item) + \"\\n\")\n",
    "    \n",
    "    ## Log Return File\n",
    "    df_logret.to_csv(\"log_ret.csv\", index=False)\n",
    "    \n",
    "    # Call R Script for fitting and forecasting garch\n",
    "    garch_script_path = \"./20220621_garch.r\"\n",
    "    subprocess.call(\"/usr/bin/Rscript \" + garch_script_path, shell=True)\n",
    "    \n",
    "    ## Get garch residuals and forecast\n",
    "    garch_resid = pd.read_csv(\"r-garch-resid.csv\")['V1']\n",
    "    \n",
    "    with open(\"r-garch-1d-forecast.txt\", \"r\") as f:\n",
    "        garch_1d_forecast = float(f.read().rstrip('\\n'))\n",
    "\n",
    "    os.remove(\"arima_model.txt\")\n",
    "    os.remove(\"log_ret.csv\")\n",
    "    os.remove(\"r-garch-resid.csv\")\n",
    "    os.remove(\"r-garch-1d-forecast.txt\")\n",
    "    \n",
    "    return  garch_1d_forecast, garch_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddad07b-832f-420c-aed1-07b31564f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Garch 1d forecast\n",
    "garch_1d_forecast, garch_resid = get_garch_1d_forecast(in_df[ticker]['log_return'], arima_best_order)\n",
    "\n",
    "## Test Ljungbox Fit\n",
    "lb_pval = ljungbox(garch_resid, lags=[arima_best_order[2]])['lb_pvalue'].values[0]\n",
    "lb_pval_2 = ljungbox(garch_resid**2, lags=[arima_best_order[2]])['lb_pvalue'].values[0]\n",
    "print(f'Ljung-Box P-Value on Residual        : {lb_pval}')\n",
    "print(f'Ljung-Box P-Value on Squared Residual: {lb_pval_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1023458c-10fe-46fb-bbd8-addaafd7f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GARCH Model Summary\n",
    "_ = tsplot(garch_resid, lags=30)\n",
    "_ = tsplot(garch_resid**2, lags=30, title='Squared Analysis Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4a14c-d3fb-4907-b464-af73e0286cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21ed9700-627b-417f-b96a-c7b741ae2a25",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735de54a-a648-4d8f-b7eb-b303cb0aced3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
